# Maestrai - Advanced Audio Transcription Service

[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Tests](https://github.com/yourusername/maestrai/workflows/tests/badge.svg)](https://github.com/yourusername/maestrai/actions)

Advanced audio and video transcription service powered by OpenAI Whisper with multi-model support, word-level timestamps, and comprehensive export options.

## âœ¨ Features

- **Multi-Model Support** - Choose from 5 Whisper models (tiny, base, small, medium, large)
- **Word-Level Timestamps** - Extract precise timing for every word
- **99+ Languages** - Support for all Whisper-compatible languages
- **Multiple Formats** - Process MP3, WAV, M4A, FLAC, OGG, WEBM audio files
- **Video Support** - Extract and transcribe audio from MP4, AVI, MOV, MKV videos
- **Export Options** - Generate SRT subtitles and formatted text transcripts
- **GPU Acceleration** - Automatic CUDA detection with CPU fallback
- **Batch Processing** - Transcribe multiple files efficiently

## ğŸš€ Quick Start

### Automated Setup (Recommended)

#### macOS/Linux:
```bash
./setup.sh
```

#### Windows:
```bash
setup.bat
```

### Manual Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install FFmpeg
# macOS:
brew install ffmpeg

# Ubuntu/Debian:
sudo apt update && sudo apt install ffmpeg
```

## ğŸ“– Usage

### Interactive Demo

```bash
python scripts/demo.py
```

### Quick Transcription

```bash
# Basic usage
python scripts/demo.py audio.mp3

# Use specific model
python scripts/demo.py audio.mp3 --model small

# Enable verbose logging
python scripts/demo.py audio.mp3 --verbose
```

### Programmatic Usage

```python
from src.transcription_engine import TranscriptionEngine

# Initialize engine
engine = TranscriptionEngine(model_name="base")

# Transcribe audio file
result = engine.transcribe("audio.mp3")

# Access results
print(f"Language: {result.language}")
print(f"Text: {result.text}")

# Export to SRT and TXT
engine.export_srt(result, "output.srt")
engine.export_txt(result, "output.txt")
```

## ğŸ“Š Model Comparison

| Model  | Speed      | Accuracy | VRAM   | Best For                |
|--------|-----------|----------|--------|-------------------------|
| tiny   | Fastest   | Good     | ~1GB   | Quick drafts, testing   |
| base   | Fast      | Better   | ~1GB   | General use, demos      |
| small  | Medium    | Great    | ~2GB   | Balanced performance    |
| medium | Slow      | Excellent| ~5GB   | High accuracy needs     |
| large  | Slowest   | Best     | ~10GB  | Professional transcripts|

## ğŸ“š Documentation

- **[Setup Guide](docs/SETUP.md)** - Complete installation and configuration
- **[Quick Reference](docs/QUICK_REFERENCE.md)** - Cheat sheet and common tasks
- **[Testing Guide](docs/TESTING.md)** - How to test the application
- **[API Documentation](docs/API.md)** - Detailed API reference
- **[Contributing](docs/CONTRIBUTING.md)** - Contribution guidelines
- **[Phase 1 Complete](docs/PHASE1_COMPLETE.md)** - Implementation details

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=src --cov-report=term-missing

# Test with your audio file
python scripts/demo.py ~/Downloads/audio.mp3 --model tiny
```

See [TESTING.md](docs/TESTING.md) for comprehensive testing guide.

## ğŸ“ Project Structure

```
maestrai/
â”œâ”€â”€ docs/                        # All documentation
â”‚   â”œâ”€â”€ README.md                # Detailed project overview
â”‚   â”œâ”€â”€ SETUP.md                 # Setup guide
â”‚   â”œâ”€â”€ QUICK_REFERENCE.md       # Quick reference guide
â”‚   â”œâ”€â”€ TESTING.md               # Testing guide
â”‚   â”œâ”€â”€ API.md                   # API documentation
â”‚   â”œâ”€â”€ CONTRIBUTING.md          # Contribution guidelines
â”‚   â””â”€â”€ PHASE1_COMPLETE.md       # Implementation summary
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ transcription_engine.py  # Core transcription logic
â”‚   â”œâ”€â”€ audio_processor.py       # Audio/video processing
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ config.py            # Configuration management
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_transcription.py    # Test suite (18 tests)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ demo.py                  # Interactive demo
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py           # Basic examples
â”‚   â”œâ”€â”€ batch_processing.py      # Batch processing
â”‚   â””â”€â”€ video_transcription.py   # Video examples
â”œâ”€â”€ setup.sh                     # macOS/Linux setup script
â”œâ”€â”€ setup.bat                    # Windows setup script
â””â”€â”€ requirements.txt             # Python dependencies
```

## ğŸ”§ Requirements

- Python 3.9+
- FFmpeg
- CUDA Toolkit (optional, for GPU acceleration)
- 4GB+ RAM (8GB+ recommended for larger models)

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [OpenAI Whisper](https://github.com/openai/whisper)
- Audio processing by [FFmpeg](https://ffmpeg.org/)

## ğŸ“ Support

- **Documentation**: See [docs/](docs/) directory
- **Issues**: Report bugs at [GitHub Issues](https://github.com/yourusername/maestrai/issues)
- **Examples**: Check [examples/](examples/) directory

## ğŸ—ºï¸ Roadmap

### Phase 1 (Current) âœ…
- Core transcription engine
- Multi-model support
- Word-level timestamps
- Export to SRT/TXT
- Batch processing

### Phase 2 (Planned)
- REST API server
- Web interface
- Real-time transcription
- Speaker diarization
- Custom vocabulary support

---

Made with â¤ï¸ by the Maestrai Team
